# è¿™æ˜¯ä¿®å¤åçš„ä»£ç ï¼Œå¯ä»¥ç›´æ¥å¤åˆ¶åˆ°ä½ çš„notebookä¸­

import os
import json
import csv
import re

# è‡ªåŠ¨æ‰«æjson_outputç›®å½•
JSON_OUTPUT_BASE_DIR = "./json_output"
CSV_OUTPUT_BASE_DIR = "./csv_output"

# Likert æ˜ å°„
LIKERT_MAP = {
    "Strongly Disagree": 1,
    "Disagree": 2,
    "Neutral": 3,
    "Agree": 4,
    "Strongly Agree": 5
}

# åå‘é¢˜ç›®ç´¢å¼•ï¼ˆæ¯ç»„ç¬¬3é¢˜ï¼‰
REVERSE_INDEXES = [2, 5, 8, 11, 14]

# BFI æ ‡å‡†åˆ—åä¸é¢˜ç›®æ˜ å°„ï¼ˆé¡ºåºå¿…é¡»å¯¹åº”ï¼‰
BFI_LABELS = [
    "BFI_11", "BFI_12", "BFI_13",
    "BFI_21", "BFI_22", "BFI_23",
    "BFI_31", "BFI_32", "BFI_33",
    "BFI_41", "BFI_42", "BFI_43",
    "BFI_51", "BFI_52", "BFI_53"
]

BFI_QUESTIONS = [
    ("Extraversion", "I am talkative."),
    ("Extraversion", "I am outgoing, sociable."),
    ("Extraversion", "I am reserved."),  # reverse
    ("Agreeableness", "I am helpful and unselfish with others."),
    ("Agreeableness", "I am generally trusting."),
    ("Agreeableness", "I am sometimes rude to others."),  # reverse
    ("Conscientiousness", "I do a thorough job."),
    ("Conscientiousness", "I make plans and follow through with them."),
    ("Conscientiousness", "I tend to be careless."),  # reverse
    ("Neuroticism", "I get nervous easily."),
    ("Neuroticism", "I worry a lot."),
    ("Neuroticism", "I am emotionally stable."),  # reverse
    ("Openness", "I have an active imagination."),
    ("Openness", "I am original, come up with new ideas."),
    ("Openness", "I have few artistic interests.")  # reverse
]

def extract_model_info_from_folder(folder_name):
    """ä»æ–‡ä»¶å¤¹åæå–æ¨¡å‹ä¿¡æ¯å’Œè¿è¡Œæ¬¡æ•°"""
    # åŒ¹é…æ ¼å¼: experiment_outputs_{model}_{run_index}
    match = re.match(r"experiment_outputs_(.+)_(\d+)", folder_name)
    if match:
        model_name = match.group(1)
        run_index = int(match.group(2))
        return model_name, run_index
    return None, None

# è‡ªåŠ¨éå†json_outputç›®å½•
if not os.path.exists(JSON_OUTPUT_BASE_DIR):
    print(f"âŒ Directory not found: {JSON_OUTPUT_BASE_DIR}")
    print("Please make sure you have run the JSON parsing step first.")
else:
    # è·å–æ‰€æœ‰å®éªŒæ–‡ä»¶å¤¹
    experiment_folders = [f for f in os.listdir(JSON_OUTPUT_BASE_DIR) 
                         if os.path.isdir(os.path.join(JSON_OUTPUT_BASE_DIR, f)) 
                         and f.startswith("experiment_outputs_")]
    
    if not experiment_folders:
        print(f"âŒ No experiment folders found in {JSON_OUTPUT_BASE_DIR}")
    else:
        print(f"ğŸ” Found {len(experiment_folders)} experiment folders")
        
        for folder_name in sorted(experiment_folders):
            model_name, run_index = extract_model_info_from_folder(folder_name)
            
            if model_name is None:
                print(f"âš ï¸ Cannot parse folder name: {folder_name}")
                continue
                
            folder_path = os.path.join(JSON_OUTPUT_BASE_DIR, folder_name)
            
            # åˆ›å»ºCSVè¾“å‡ºç›®å½•
            os.makedirs(CSV_OUTPUT_BASE_DIR, exist_ok=True)
            output_csv = os.path.join(CSV_OUTPUT_BASE_DIR, f"{model_name}_{run_index}.csv")

            print(f"ğŸ“ Processing folder: {folder_name} â†’ {output_csv}")

            data_rows = []
            skipped_files = []

            for file in os.listdir(folder_path):
                if (file.endswith(".json") 
                    and not file.startswith(".") 
                    and "-checkpoint" not in file):
                    filepath = os.path.join(folder_path, file)
                    try:
                        with open(filepath, "r") as f:
                            data = json.load(f)

                        flat = {
                            "sample_id": data.get("sample_id"),
                            "ad_type": data.get("ad_type")
                        }
                        # è‡ªåŠ¨å±•å¼€ profile å­—æ®µ
                        profile = data.get("profile", {})
                        for key, value in profile.items():
                            # å°†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦è½¬ä¸ºä¸‹åˆ’çº¿ï¼Œç»Ÿä¸€å­—æ®µåæ ¼å¼
                            col_name = key.strip().lower().replace(" ", "_").replace("-", "_")
                            flat[col_name] = value
                        # æ›¿æ¢ BFI é—®é¢˜ä¸ºæ ‡å‡†åˆ—å + Likert æ˜ å°„ + åå‘é¢˜å¤„ç†
                        for i, (_, q) in enumerate(BFI_QUESTIONS):
                            label = BFI_LABELS[i]
                            val = data["traits"].get(q, "")
                            numeric = LIKERT_MAP.get(val, "")
                            if numeric != "":
                                if i in REVERSE_INDEXES:
                                    numeric = 6 - numeric  # åå‘è®¡åˆ†
                            flat[label] = numeric

                        # æå–å¹¿å‘Šè¯„ä»·åˆ†æ•° - åªä¿ç•™å‰4ä¸ª
                        ad_scores = data.get("ad_attitude_scores", [])
                        for i, score in enumerate(ad_scores[:4], 1):  # åªå–å‰4ä¸ª
                            flat[f"ad_att_{i}"] = score

                        # ä¿®å¤æ‹¼é”™çš„å­—æ®µå - åªä¿ç•™å‰3ä¸ª
                        intent_scores = data.get("purchase_intention_scores") or data.get("purchase_intension_scores") or []
                        for i, score in enumerate(intent_scores[:3], 1):  # åªå–å‰3ä¸ª
                            flat[f"intent_{i}"] = score

                        data_rows.append(flat)

                    except Exception as e:
                        skipped_files.append((file, str(e)))
                        print(f"âš ï¸ Skipped {file}: {e}")

            # å†™å…¥ CSV - æ³¨æ„ç¼©è¿›ï¼Œè¿™åº”è¯¥åœ¨forå¾ªç¯å†…éƒ¨
            if data_rows:
                fieldnames = ["sample_id", "ad_type", "gender", "age", "education", "occupation", "marital_status", "monthly_income", "region"] + BFI_LABELS + \
                             [f"ad_att_{i}" for i in range(1, 5)] + \
                             [f"intent_{i}" for i in range(1, 4)]

                data_rows.sort(key=lambda x: (x["sample_id"], x["ad_type"]))

                with open(output_csv, "w", newline="") as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(data_rows)

                print(f"âœ… CSV saved: {output_csv} with {len(data_rows)} records.")
            else:
                print(f"âš ï¸ No valid data in {folder_name}")
